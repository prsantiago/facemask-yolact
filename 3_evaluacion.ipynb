{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_evaluacion.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1SZ3XNkn3zzin06Xw_NvA84Ejg4nlTW3Y","authorship_tag":"ABX9TyPDDhIPhEqOX1WqoxD6lG+6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H3As9fUSvbHA"},"source":["#**Evaluación**\r\n","---\r\n","\r\n","En este notebook se evaluará el modelo para poder analizar los resultados obtenidos. Existen varios tipos de evaluación, los cuales se presentan en la documentación de [Yolact](https://www.github.com/dbolya/yolact), sin embargo, en este proyecto se centrará en la evaluación de las imágenes de prueba, un video y de resultados cuantitativos. Finalmente se desplegarán los dos primeros una vez procesados."]},{"cell_type":"markdown","metadata":{"id":"4MwQzXuLOx4T"},"source":["#**Repositorios que se usarán**\r\n","---\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"SMTAYwxA5a2d"},"source":["Se clonan los siguientes repositorios:\r\n","*   [facemask-yolact](https://github.com/prsantiago/facemask-yolact) contiene la arquitectura.\r\n","*   [facemask-dataset](https://github.com/prsantiago/facemask-dataset) contiene el dataset (entrenamiento, validación y prueba) que se usa."]},{"cell_type":"code","metadata":{"id":"WxcLVt8iO114"},"source":["%cd /content\r\n","!git clone https://github.com/prsantiago/facemask-yolact\r\n","!git clone https://github.com/prsantiago/facemask-dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YhgR2fK8Fiq9"},"source":["#**Carga del modelo**\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"UyPGx6mlFIEA"},"source":["Primero se crea la carpeta donde se almacenarán los pesos a valorar"]},{"cell_type":"code","metadata":{"id":"Vy4p9bDEFHzr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614467819552,"user_tz":360,"elapsed":430,"user":{"displayName":"SANTIAGO PE�A RODRIGUEZ","photoUrl":"","userId":"09250284461639194420"}},"outputId":"4684f2fd-405d-4173-d220-5573c54c21e6"},"source":["%cd /content/facemask-yolact\n","!mkdir -p weights"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/facemask-yolact\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mkmgcZOCGYQO"},"source":["Se copia a la carpeta desde la ruta donde se guardó el modelo en el notebook de Entrenamiento"]},{"cell_type":"code","metadata":{"id":"5LeVYq2Jnm86"},"source":["!cp /content/drive/MyDrive/PT/YOLACT_output/v10/yolact_facemask_416_40000.pth /content/facemask-yolact/weights/yolact_facemask_416_40000.pth"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jc9cYoOMHBU0"},"source":["#**Evaluación visual del modelo**\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"OwJNs-G7FHdD"},"source":["Primero se cerciora de que la carpeta donde se guardarán las imágenes procesadas esté vacía al eliminarla y posteriormente volverla a crear."]},{"cell_type":"code","metadata":{"id":"IEB1lock-2hD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614469063400,"user_tz":360,"elapsed":456,"user":{"displayName":"SANTIAGO PE�A RODRIGUEZ","photoUrl":"","userId":"09250284461639194420"}},"outputId":"a0b3e2ee-a6d9-45f7-b4e5-e5322b116ac8"},"source":["!rm /content/output_images -r\r\n","!mkdir -p /content/output_images"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rm: cannot remove '/content/output_images': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sYl3q2KNHrf4"},"source":["El siguiente comando es para evaluar un video. \r\n","\r\n","```\r\n","--video=/carpeta/donde/esta/video:/carpeta/donde/guardar/video\r\n","```\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"k02qQbjS_I5i"},"source":["%cd /content/facemask-yolact\n","!python eval.py --video=/content/drive/MyDrive/PT/IMG_1441.mp4:/content/IMG_1441.mp4 --display_fps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bur3nAWJGJk"},"source":["El siguiente comando es para evaluar un conjunto de imagenes. \r\n","\r\n","*Además brinda la relación de detecciones hechas entre detecciones correctas posibles para cada categoría*\r\n","\r\n","```\r\n","--images=/carpeta/donde/estan/imagenes:/carpeta/donde/guardar/imagenes\r\n","```"]},{"cell_type":"code","metadata":{"id":"auWHGuW0_OKS"},"source":["%cd /content/facemask-yolact\n","!python eval.py --images=/content/facemask-dataset/test_images:/content/output_images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEP9dcg3gyUz"},"source":["#**Evaluación cuantitativa del modelo**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"1-uVdwFB7Xbc"},"source":["Para producir los resultados cuantitativos del modelo se ejecuta la siguiente celda:\r\n","\r\n","*Las métricas que brinda son: calificación mAP en la generación de la máscara y la caja, número de imágenes capaz de procesar en un segundo, y la relación de detecciones hechas entre detecciones correctas posibles para cada categoría*"]},{"cell_type":"code","metadata":{"id":"eNg6YfkNpw5g"},"source":["%cd /content/facemask-yolact\n","!python eval.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pU6BXwjLJd4s"},"source":["#**Análisis de resultados**\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a9E7sMr1OJmn"},"source":["Código para visualizar las imágenes de prueba que han sido procesadas. Se siguió la implementación de la [celda](https://colab.research.google.com/drive/1ncRxvmNR-iTtQCscj2UFSGV8ZQX_LN0M#scrollTo=4U2u5-LKOHeV) que se utiliza en el siguiente [tutorial](https://www.immersivelimit.com/tutorials/yolact-with-google-colab)."]},{"cell_type":"code","metadata":{"id":"3VdgnbzN_WmD"},"source":["import cv2\r\n","import numpy as np\r\n","from matplotlib import pyplot as plt\r\n","from pathlib import Path\r\n","from IPython.display import Image\r\n","\r\n","\r\n","output_images = Path('/content/output_images')\r\n","\r\n","def show_image(img_path):\r\n","  img = cv2.imread(img_path)\r\n","  img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n","  plt.figure(figsize=(8,8))\r\n","  plt.imshow(img_cvt)\r\n","  plt.show()\r\n","\r\n","# Iterate through all of the output images and display them\r\n","for img_path in output_images.iterdir():\r\n","  print(img_path)\r\n","  show_image(str(img_path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3hzUl6wP_Ovc"},"source":["Código para visualizar el video que ha sido procesado. Se siguió la implementación de la [celda](https://colab.research.google.com/github/vindruid/yolov3-in-colab/blob/master/yolov3_video.ipynb#scrollTo=osBzRGoxMAE9) que se utiliza en el siguiente [tutorial](https://www.towardsdatascience.com/yolov3-pytorch-on-google-colab-c4a79eeecdea)."]},{"cell_type":"code","metadata":{"id":"uaKwqYCA0JxE"},"source":["from IPython.display import HTML\r\n","from base64 import b64encode\r\n","import os\r\n","\r\n","# Input video path\r\n","save_path = \"/content/IMG_1441.mp4\"\r\n","\r\n","# Compressed video path\r\n","compressed_path = \"/content/IMG_1441_compressed.mp4\"\r\n","os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\r\n","\r\n","# Show video\r\n","mp4 = open(compressed_path,'rb').read()\r\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\r\n","HTML(\"\"\"\r\n","<video width=400 controls>\r\n","      <source src=\"%s\" type=\"video/mp4\">\r\n","</video>\r\n","\"\"\" % data_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fVuq4BvFKBwz"},"source":["(OPCIONAL) Se guardan las fotos procesadas en la ruta Drive especificada"]},{"cell_type":"code","metadata":{"id":"hqpHRulu_XzH"},"source":["!cp -r /content/output_images /content/drive/MyDrive/PT/YOLACT_output/v10/test_images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8YLfP1mmAKrz"},"source":["(OPCIONAL) Se guarda el video procesado en la ruta Drive especificada"]},{"cell_type":"code","metadata":{"id":"UUWFWONF__lk"},"source":["!cp -r /content/IMG_1441.mp4 /content/drive/MyDrive/PT/YOLACT_output/v10/IMG_1441.mp4"],"execution_count":null,"outputs":[]}]}