{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_acondicionamiento_imagenes.ipynb","provenance":[],"mount_file_id":"165lh2onF2asnDUs-mcjcigO0LTIpTuSW","authorship_tag":"ABX9TyNHPYRN95s/9/djX94H+Z7z"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"l5jK0NaLUXWd"},"source":["#**Acondicionamiento de imágenes**\r\n","\r\n","---\r\n","\r\n","En este notebook se prepara el conjunto de imágenes que se utilizarán en el proyecto para que todas tengan dimensiones homogeneas\r\n","de 550 x 550 pixeles con el uso del script [size_pad_images.py](https://www.github.com/howl0893/custom-object-detection-datasets/blob/master/python/size_pad_images.py). Se continua con la elaboración de las anotaciones para cada una usando la herramienta [labelme](https://www.github.com/wkentaro/labelme) (externa a este notebook). Por último, se recopila el dataset con conformado por imágenes y un archivo JSON maestro con todas las anotaciones, con el uso del scrypt [labelme2coco.py](https://www.github.com/wkentaro/labelme/blob/master/examples/instance_segmentation/labelme2coco.py) que se proveé en dicho software."]},{"cell_type":"markdown","metadata":{"id":"Y-YTwmDACSiZ"},"source":["#**Repositorio que se usará**\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f2JgaLwgCYKF"},"source":["Ya que se le hicieron cambios a los scripts originales, estos fueron incorporados con dichas modificaciones al repositorio del proyecto.\n","*   [facemask-yolact](https://github.com/prsantiago/facemask-yolact) "]},{"cell_type":"code","metadata":{"id":"cANL84iDCCdD"},"source":["%cd /content\n","!git clone https://github.com/prsantiago/facemask-yolact"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cv0aS359FypH"},"source":["#**Transformaciones que se harán**\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ACChiJ8lFoRV"},"source":["Se redimencionan las imágenes de entrenamiento y validación a tamaño 550x550. Este requisito se brinda explícitamente en el script.\n","\n","*Importante recalcar que las carpetas de entrada y salida que se proporcionan se encuentran en el Drive de la máquina local.*\n","\n","```\n","python size_pad_images.py carpeta/imagenes/entrada carpeta/imagenes/salida\n","```\n"]},{"cell_type":"code","metadata":{"id":"zLMJHPDyFncL"},"source":["%cd /content/facemask-yolact/acondicionamiento\n","!python size_pad_images.py ../../drive/MyDrive/PT/pre_dataset/train ../../drive/MyDrive/PT/dataset/train\n","!python size_pad_images.py ../../drive/MyDrive/PT/pre_dataset/val ../../drive/MyDrive/PT/dataset/val"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bjp0NVkaPL71"},"source":["#**Anotaciones COCO**"]},{"cell_type":"markdown","metadata":{"id":"xiZd1xYEPfVI"},"source":["Una vez que se cuentan con las anotaciones en forma de JSON de cada imagen del dataset, estas se juntamn en un mismo archivo JSON que está en formato COCO. (train y val tendrán sus propias anotaciones)\r\n","\r\n","*Importante recalcar que las carpetas de entrada y salida que se proporcionan se encuentran en el Drive de la máquina local.*"]},{"cell_type":"markdown","metadata":{"id":"j8YWRGSiUgt5"},"source":["\n","\n","```\n","python labelme2coco.py carpeta/anotaciones/entrada carpeta/anotaciones/COCO --labels archivo_clases_detectar.txt\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"ajyUygRSIjNW"},"source":["%cd /content/facemask-yolact/acondicionamiento\n","!python labelme2coco.py ../../drive/MyDrive/PT/dataset/train ../../drive/MyDrive/PT/dataset/coco/train --labels labels.txt\n","!python labelme2coco.py ../../drive/MyDrive/PT/dataset/val ../../drive/MyDrive/PT/dataset/coco/val --labels labels.txt"],"execution_count":null,"outputs":[]}]}